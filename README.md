# Scraper de Port√°tiles en √âxito

Este proyecto es un script de Python dise√±ado para realizar web scraping de la secci√≥n de port√°tiles en el sitio web de [√âxito](https://www.exito.com/tecnologia/computadores/portatiles). Utiliza **Selenium** y **BeautifulSoup** para extraer informaci√≥n detallada de cada producto, incluyendo marca, nombre, precio actual y precio original.

![alt text](https://forbes.co/_next/image?url=https%3A%2F%2Fcdn.forbes.co%2F2020%2F03%2FGrupo-%C3%89xito-1280x720-1.jpg%3Fv%3D1280720&w=3840&q=75)

## üìã Requisitos

- **Python 3.7 o superior:** Aseg√∫rate de tener instalada una versi√≥n reciente de Python.
- **Mozilla Firefox:** El script utiliza Firefox como navegador para Selenium.
- **Git:**  Para clonar el repositorio.
- **Conexi√≥n a Internet:** Para descargar el controlador de Firefox y acceder al sitio web.

## üîß Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/JohanMorales211/script-scraping-web.git
cd script-scraping-web
```

### 2. Crear un Entorno Virtual

```bash
python3 -m venv venv
```

### 3. Activar el Entorno Virtual

- En Windows:

```bash
venv\Scripts\activate
```

- En macOS y Linux:

```bash
source venv/bin/activate
```

### 4. Instalar las Dependencias

```bash
pip install -r requirements.txt
```

## üöÄ Uso

```bash
python nombre_archivo.py
```

## üîç ¬øQu√© Hace el Script?

1. **Navega a la P√°gina Inicial:** Accede a la p√°gina de port√°tiles en √âxito.
2. **Extrae el Conteo Total de Productos:** Obtiene el n√∫mero total de productos disponibles.
3. **Calcula el N√∫mero de P√°ginas:** Determina cu√°ntas p√°ginas se deben scrapear.
4. **Itera Sobre Cada P√°gina:** Extrae la informaci√≥n de cada port√°til:
    - Marca
    - Nombre
    - Precio Actual
    - Precio Original
5. **Guarda los Datos en un CSV:** Almacena los datos en `portatiles_exito.csv`.

## üìù Notas Adicionales

- **Modo Headless:** El script se ejecuta en modo headless (sin ventana del navegador visible).
- **Manejo de Errores:** El script contin√∫a ejecut√°ndose incluso si encuentra errores en algunas p√°ginas.
- **Registros de Ejecuci√≥n:** Se recomienda implementar registros con la biblioteca `logging`.


## üõ†Ô∏è Soluci√≥n de Problemas
**‚ùå Error `NoSuchElementError`**

**Descripci√≥n del Error:**

`NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5` (o similar)

**Causas Probables:**

- **Clases CSS Cambiadas:** Las clases CSS para identificar los productos pueden haber sido modificadas en el sitio web.
- **Contenido Diferente:**  La estructura HTML de las p√°ginas puede haber cambiado.
- **Tiempo de Espera Insuficiente:** El script puede estar intentando acceder a elementos antes de que carguen completamente.
- **Limitaciones del Servidor:** El sitio web puede estar implementando medidas anti-scraping.

**Pasos para Resolver:**

1. **Verificar Manualmente:** Inspecciona el c√≥digo fuente de las p√°ginas con problemas usando las herramientas de desarrollo del navegador (F12).
2. **Actualizar Selectores:** Ajusta los selectores CSS en el script para que coincidan con las nuevas clases o estructura HTML.
3. **Aumentar Tiempo de Espera:** Incrementa el tiempo de espera en `WebDriverWait` para dar tiempo a que los elementos carguen.
4. **Implementar Retries:** Agrega l√≥gica para reintentar la extracci√≥n de datos en caso de fallo.
5. **Analizar Anti-Scraping:** Considera usar pausas aleatorias, rotar user-agents o proxies.

## üìÑ `requirements.txt`

```plaintext
attrs==24.2.0
beautifulsoup4==4.12.3
certifi==2024.8.30
charset-normalizer==3.4.0
h11==0.14.0
idna==3.10
numpy==2.1.3
outcome==1.3.0.post0
packaging==24.1
pandas==2.2.3
PySocks==1.7.1
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
pytz==2024.2
requests==2.32.3
selenium==4.26.1
six==1.16.0
sniffio==1.3.1
sortedcontainers==2.4.0
soupsieve==2.6
trio==0.27.0
trio-websocket==0.11.1
typing_extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
webdriver-manager==4.0.2
websocket-client==1.8.0
wsproto==1.2.0
```

## üßë‚Äçüíª Instrucciones Adicionales

1. **Instalar Firefox:** Aseg√∫rate de tener instalado Firefox.
2. **Compatibilidad de Versiones:** `webdriver-manager` gestiona la descarga de GeckoDriver.
3. **Ejecuci√≥n:** Activa el entorno virtual y ejecuta `python scraping_portatiles_exito.py`.
4. **Salida:** El script crea `portatiles_exito.csv`.
